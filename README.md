
# Reducing Gender Bias in Word Embeddings

This project was completed as a part of the Honors portion of the [Sequence Models](https://www.coursera.org/learn/nlp-sequence-models) Course on [Coursera](https://www.coursera.org/).

Credit to DeepLearning.AI and the Coursera platform for providing the course materials and guidance.

## Objective

In this notebook, my objective is to explore the world of word embeddings, which are computationally expensive to train. Instead of training from scratch, I will focus on loading and working with pre-trained embeddings. Through this assignment, I will gain valuable insights into how word embeddings capture meaningful relationships between words and how to measure similarity using cosine similarity.

By the end of this task, I will be able to load pre-trained word vectors and utilize them to solve word analogy problems, such as finding the relationship between words "Man" and "Woman" and applying it to "King" to discover the missing term.

Furthermore, I will have the opportunity to engage in an optional exercise to modify word embeddings and reduce their gender bias. As reducing bias is a significant consideration in machine learning, I am encouraged to take up this challenge.

Ultimately, this assignment will equip me with the skills to handle pre-trained word embeddings effectively, enabling me to analyze word relationships, measure similarity, and address potential biases for more robust natural language processing tasks.
## Results

![Reducing Gender Bias in Word Embeddings](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiKL-4YgQch-24IcxXLIklbrWCm3_IgU6P3HoApq3Em4mEs2wtUGrV1HoBykIHfcZWcjkNr0CoBtbywX_dDtp3YsmjRENuF8CeZxSauoj2Rle_jBabq_HrbnfpivfpxTBE5EQgnTUrp4LSNAriafvbsO52dnRRHA3uIiXk7BUpOKsrDoOq_IF_2bbl3Ul0/s1600/reducing-gender-bias-in-word-embeddings.png)